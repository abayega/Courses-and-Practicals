{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phyla_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abayega/Courses-and-Practicals/blob/master/phyla_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDRY2ExqDELU"
      },
      "source": [
        "# Very basic microbiome data classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85DT6Sln4eEx"
      },
      "source": [
        "PyTorch Cancer Classification Pipeline\r\n",
        "Copy of AIforGenomics_2021_session_2.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP9m_23cA9ds"
      },
      "source": [
        "#Import packages\r\n",
        "\r\n",
        "import os\r\n",
        "from IPython.display import Image\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\r\n",
        "\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.datasets import MNIST, ImageFolder\r\n",
        "from torchvision.utils import make_grid, save_image\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import matplotlib\r\n",
        "import seaborn as sns; sns.set()\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1e_r-EeBFfS",
        "outputId": "7f91cb6c-aa74-4e64-b6e5-926cb58f9c8e"
      },
      "source": [
        "#Load google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlRgq58nBVJo"
      },
      "source": [
        "#Read data file\r\n",
        "data_file = F'/content/gdrive/MyDrive/PhD/Coursework/AI in Genomics/Projects/Phyla/phyla_dataset_d3/phyla_dataset_d3.csv'\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk8p7QWKEGt-"
      },
      "source": [
        "#Pandas data read\r\n",
        "microbe_df = pd.read_csv(data_file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOw6CV41F0SI",
        "outputId": "a5803777-ac4c-49b7-9ae8-2ee153a54679"
      },
      "source": [
        "#Pandas data view\r\n",
        "print(microbe_df.iloc[1:4,1178:1184])\r\n",
        "print(microbe_df.iloc[1:4,1:2])\r\n",
        "#microbe_df.groupby(['col_site','uc_cd']).uc_cd.count()\r\n",
        "#microbe_df.groupby(['col_site','stool_biopsy']).stool_biopsy.count()\r\n",
        "#microbe_df.col_site.value_counts()\r\n",
        "#microbe_df.uc_cd.value_counts()\r\n",
        "#microbe_df.stool_biopsy.value_counts()\r\n",
        "#microbe_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  col_site  diagnosis sample_title stool_biopsy  studyID uc_cd\n",
            "1   OSCCAR          1  1939.100003        stool  GEVERSM    CD\n",
            "2   OSCCAR          1  1939.100009        stool  GEVERSM    UC\n",
            "3   OSCCAR          1  1939.100015        stool  GEVERSM    CD\n",
            "   D_0__Archaea;D_1__Euryarchaeota;D_2__Halobacteria;D_3__Halobacteriales;D_4__Halococcaceae;__\n",
            "1                                                0.0                                           \n",
            "2                                                0.0                                           \n",
            "3                                                0.0                                           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6ELJZnpDcmU"
      },
      "source": [
        "https://towardsdatascience.com/a-beginners-tutorial-on-building-an-ai-image-classifier-using-pytorch-6f85cb69cba7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slUPp4ZplSuN"
      },
      "source": [
        "#3 Now, we get the features and metadata\r\n",
        "\r\n",
        "expr_df = microbe_df.iloc[:,1:1177]\r\n",
        "phenotype_df_neat = microbe_df.iloc[:,1178:1184]\r\n",
        "phenotype_df = phenotype_df_neat\r\n",
        "\r\n",
        "#We can set 'sample_title' as index by:\r\n",
        "phenotype_df.set_index('sample_title')\r\n",
        "\r\n",
        "#Let's covert UC and CD to IBD\r\n",
        "#df.loc[df['column'] == 'column_value', 'column'] = 'new_column_value' or df.loc[(df.column == 'column_value'), 'column'] = 'new_column_value'\r\n",
        "\r\n",
        "#phenotype_df.loc[phenotype_df['uc_cd'] == 'CD', 'uc_cd'] = 'IBD'\r\n",
        "#phenotype_df.loc[phenotype_df['uc_cd'] == 'UC', 'uc_cd'] = 'IBD'\r\n",
        "\r\n",
        "phenotype_df.loc[(phenotype_df.uc_cd == 'CD'), 'uc_cd'] = 'IBD'\r\n",
        "phenotype_df.loc[(phenotype_df.uc_cd == 'UC'), 'uc_cd'] = 'IBD'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "VWpfntZm0om-",
        "outputId": "ecf2c8da-689a-4ec3-85a7-81b5c14a7b01"
      },
      "source": [
        "phenotype_df"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_site</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>sample_title</th>\n",
              "      <th>stool_biopsy</th>\n",
              "      <th>studyID</th>\n",
              "      <th>uc_cd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OSCCAR</td>\n",
              "      <td>1</td>\n",
              "      <td>1939.100001</td>\n",
              "      <td>stool</td>\n",
              "      <td>GEVERSM</td>\n",
              "      <td>IBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OSCCAR</td>\n",
              "      <td>1</td>\n",
              "      <td>1939.100003</td>\n",
              "      <td>stool</td>\n",
              "      <td>GEVERSM</td>\n",
              "      <td>IBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OSCCAR</td>\n",
              "      <td>1</td>\n",
              "      <td>1939.100009</td>\n",
              "      <td>stool</td>\n",
              "      <td>GEVERSM</td>\n",
              "      <td>IBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OSCCAR</td>\n",
              "      <td>1</td>\n",
              "      <td>1939.100015</td>\n",
              "      <td>stool</td>\n",
              "      <td>GEVERSM</td>\n",
              "      <td>IBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OSCCAR</td>\n",
              "      <td>1</td>\n",
              "      <td>1939.100016</td>\n",
              "      <td>stool</td>\n",
              "      <td>GEVERSM</td>\n",
              "      <td>IBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5262</th>\n",
              "      <td>AG</td>\n",
              "      <td>0</td>\n",
              "      <td>10317.000001870</td>\n",
              "      <td>stool</td>\n",
              "      <td>AG</td>\n",
              "      <td>Control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5263</th>\n",
              "      <td>AG</td>\n",
              "      <td>0</td>\n",
              "      <td>10317.000013111</td>\n",
              "      <td>stool</td>\n",
              "      <td>AG</td>\n",
              "      <td>Control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5264</th>\n",
              "      <td>AG</td>\n",
              "      <td>0</td>\n",
              "      <td>10317.000010960</td>\n",
              "      <td>stool</td>\n",
              "      <td>AG</td>\n",
              "      <td>Control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5265</th>\n",
              "      <td>AG</td>\n",
              "      <td>0</td>\n",
              "      <td>10317.000013005</td>\n",
              "      <td>stool</td>\n",
              "      <td>AG</td>\n",
              "      <td>Control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5266</th>\n",
              "      <td>AG</td>\n",
              "      <td>0</td>\n",
              "      <td>10317.000011171</td>\n",
              "      <td>stool</td>\n",
              "      <td>AG</td>\n",
              "      <td>Control</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5267 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     col_site  diagnosis     sample_title stool_biopsy  studyID    uc_cd\n",
              "0      OSCCAR          1      1939.100001        stool  GEVERSM      IBD\n",
              "1      OSCCAR          1      1939.100003        stool  GEVERSM      IBD\n",
              "2      OSCCAR          1      1939.100009        stool  GEVERSM      IBD\n",
              "3      OSCCAR          1      1939.100015        stool  GEVERSM      IBD\n",
              "4      OSCCAR          1      1939.100016        stool  GEVERSM      IBD\n",
              "...       ...        ...              ...          ...      ...      ...\n",
              "5262       AG          0  10317.000001870        stool       AG  Control\n",
              "5263       AG          0  10317.000013111        stool       AG  Control\n",
              "5264       AG          0  10317.000010960        stool       AG  Control\n",
              "5265       AG          0  10317.000013005        stool       AG  Control\n",
              "5266       AG          0  10317.000011171        stool       AG  Control\n",
              "\n",
              "[5267 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvhgIVseoB9H"
      },
      "source": [
        "class MicrobDataset(Dataset):\r\n",
        "  \"\"\"\r\n",
        "  Dataset for binary classification Tumor/Normal\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self):\r\n",
        "    \r\n",
        "    # Select rows whose type is Tumor or Normal\r\n",
        "    self.labels = phenotype_df[phenotype_df[\"uc_cd\"].apply(lambda s: s == \"IBD\" or s == \"Control\")]\r\n",
        "\r\n",
        "    # Compute categorical embedding, 0 is Normal, 1 is Tumor\r\n",
        "    self.labels = self.labels[\"uc_cd\"].apply(lambda s: s == \"Control\").astype(int)\r\n",
        "\r\n",
        "    # Get corresponding gene expression profiles\r\n",
        "    self.X = expr_df\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    sample = np.array(self.X.iloc[index], dtype=np.float32)\r\n",
        "    label = np.array(self.labels.iloc[index], dtype=np.float32)\r\n",
        "\r\n",
        "    return sample, label\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.labels)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZFhUDRUp4vF"
      },
      "source": [
        "dataset = MicrobDataset()\r\n",
        "num_examples, num_genes = dataset.X.shape"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPE9ZllQqzQd",
        "outputId": "7040a6f5-e5b1-45e8-d534-913c1f9f95b0"
      },
      "source": [
        "print(\"Dataset for IBD/Control classification created with\", num_examples, \r\n",
        "      \"number of samples. Each sample contains the expression levels of\", num_genes, \"OTUs.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset for IBD/Control classification created with 5267 number of samples. Each sample contains the expression levels of 1176 OTUs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfUcq-Hv2Gsh"
      },
      "source": [
        "train_set_size = int(len(dataset) * 0.7)\r\n",
        "test_set_size = len(dataset) - train_set_size"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9WfcjM52IKf"
      },
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, \r\n",
        "                                                            lengths=[train_set_size, test_set_size], \r\n",
        "                                                            generator=torch.Generator().manual_seed(0))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFq3_yX62SO_"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\r\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7QLmQgv2WVb"
      },
      "source": [
        "class LogisticRegression(nn.Module):\r\n",
        "  def __init__(self, input_dim):\r\n",
        "      super(LogisticRegression, self).__init__()\r\n",
        "\r\n",
        "      # Initialize linear layer ()\r\n",
        "      self.linear = nn.Linear(input_dim, 1)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.linear(x)  # Compute beta . x\r\n",
        "    # We do not apply the sigmoid here, as it will be applied within the criterion function (for numerical stability)\r\n",
        "    return x"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUspESAY2bPK"
      },
      "source": [
        "model = LogisticRegression(num_genes)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEOjyRN03KF3"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCULQZaT3NWn"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N87CNiD92fVm"
      },
      "source": [
        "def compute_accuracy(loader, net):\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  with torch.no_grad():\r\n",
        "      for data in loader:\r\n",
        "          inputs, labels = data\r\n",
        "          outputs = net(inputs)\r\n",
        "          predicted = (outputs > 0).int().T\r\n",
        "\r\n",
        "          total += labels.size(0)\r\n",
        "          correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "  return 100 * correct / total"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsN3zeFhDr67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ebf9f3-758a-491c-937d-64fce0d517c5"
      },
      "source": [
        "for epoch in range(100):  # loop over the dataset multiple times\r\n",
        "\r\n",
        "    running_loss = 0.0\r\n",
        "    for i, data in enumerate(train_loader, 0):\r\n",
        "        # get the inputs; data is a list of [inputs, labels]\r\n",
        "        inputs, labels = data\r\n",
        "\r\n",
        "        # zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # forward + backward + optimize\r\n",
        "        outputs = model(inputs)\r\n",
        "        loss = criterion(outputs[:, 0], labels)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()  # Update the parameters of the model\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\r\n",
        "            print('[%d, %5d] loss: %.3f' %\r\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\r\n",
        "            running_loss = 0.0\r\n",
        "\r\n",
        "print('Finished Training')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    50] loss: 33.903\n",
            "[1,   100] loss: 29.338\n",
            "[2,    50] loss: 29.923\n",
            "[2,   100] loss: 21.507\n",
            "[3,    50] loss: 22.700\n",
            "[3,   100] loss: 18.701\n",
            "[4,    50] loss: 17.327\n",
            "[4,   100] loss: 14.619\n",
            "[5,    50] loss: 12.868\n",
            "[5,   100] loss: 13.020\n",
            "[6,    50] loss: 12.581\n",
            "[6,   100] loss: 10.162\n",
            "[7,    50] loss: 11.532\n",
            "[7,   100] loss: 8.143\n",
            "[8,    50] loss: 8.541\n",
            "[8,   100] loss: 8.885\n",
            "[9,    50] loss: 8.619\n",
            "[9,   100] loss: 7.405\n",
            "[10,    50] loss: 8.162\n",
            "[10,   100] loss: 6.145\n",
            "[11,    50] loss: 6.112\n",
            "[11,   100] loss: 7.040\n",
            "[12,    50] loss: 6.971\n",
            "[12,   100] loss: 4.778\n",
            "[13,    50] loss: 5.731\n",
            "[13,   100] loss: 5.352\n",
            "[14,    50] loss: 4.365\n",
            "[14,   100] loss: 5.289\n",
            "[15,    50] loss: 4.314\n",
            "[15,   100] loss: 4.223\n",
            "[16,    50] loss: 3.301\n",
            "[16,   100] loss: 4.435\n",
            "[17,    50] loss: 3.648\n",
            "[17,   100] loss: 3.091\n",
            "[18,    50] loss: 3.122\n",
            "[18,   100] loss: 3.563\n",
            "[19,    50] loss: 3.128\n",
            "[19,   100] loss: 2.607\n",
            "[20,    50] loss: 2.639\n",
            "[20,   100] loss: 2.818\n",
            "[21,    50] loss: 2.658\n",
            "[21,   100] loss: 2.411\n",
            "[22,    50] loss: 2.424\n",
            "[22,   100] loss: 2.287\n",
            "[23,    50] loss: 2.045\n",
            "[23,   100] loss: 2.259\n",
            "[24,    50] loss: 2.061\n",
            "[24,   100] loss: 1.648\n",
            "[25,    50] loss: 1.608\n",
            "[25,   100] loss: 1.873\n",
            "[26,    50] loss: 1.791\n",
            "[26,   100] loss: 1.449\n",
            "[27,    50] loss: 1.579\n",
            "[27,   100] loss: 1.351\n",
            "[28,    50] loss: 1.722\n",
            "[28,   100] loss: 1.077\n",
            "[29,    50] loss: 1.367\n",
            "[29,   100] loss: 1.184\n",
            "[30,    50] loss: 1.093\n",
            "[30,   100] loss: 1.086\n",
            "[31,    50] loss: 0.886\n",
            "[31,   100] loss: 1.257\n",
            "[32,    50] loss: 0.950\n",
            "[32,   100] loss: 1.102\n",
            "[33,    50] loss: 0.886\n",
            "[33,   100] loss: 0.954\n",
            "[34,    50] loss: 0.919\n",
            "[34,   100] loss: 0.860\n",
            "[35,    50] loss: 0.915\n",
            "[35,   100] loss: 0.751\n",
            "[36,    50] loss: 0.719\n",
            "[36,   100] loss: 0.838\n",
            "[37,    50] loss: 0.721\n",
            "[37,   100] loss: 0.824\n",
            "[38,    50] loss: 0.645\n",
            "[38,   100] loss: 0.750\n",
            "[39,    50] loss: 0.730\n",
            "[39,   100] loss: 0.552\n",
            "[40,    50] loss: 0.626\n",
            "[40,   100] loss: 0.610\n",
            "[41,    50] loss: 0.535\n",
            "[41,   100] loss: 0.674\n",
            "[42,    50] loss: 0.612\n",
            "[42,   100] loss: 0.589\n",
            "[43,    50] loss: 0.497\n",
            "[43,   100] loss: 0.575\n",
            "[44,    50] loss: 0.515\n",
            "[44,   100] loss: 0.575\n",
            "[45,    50] loss: 0.519\n",
            "[45,   100] loss: 0.474\n",
            "[46,    50] loss: 0.437\n",
            "[46,   100] loss: 0.474\n",
            "[47,    50] loss: 0.384\n",
            "[47,   100] loss: 0.499\n",
            "[48,    50] loss: 0.440\n",
            "[48,   100] loss: 0.475\n",
            "[49,    50] loss: 0.458\n",
            "[49,   100] loss: 0.429\n",
            "[50,    50] loss: 0.490\n",
            "[50,   100] loss: 0.364\n",
            "[51,    50] loss: 0.412\n",
            "[51,   100] loss: 0.360\n",
            "[52,    50] loss: 0.344\n",
            "[52,   100] loss: 0.478\n",
            "[53,    50] loss: 0.416\n",
            "[53,   100] loss: 0.442\n",
            "[54,    50] loss: 0.364\n",
            "[54,   100] loss: 0.359\n",
            "[55,    50] loss: 0.367\n",
            "[55,   100] loss: 0.427\n",
            "[56,    50] loss: 0.398\n",
            "[56,   100] loss: 0.330\n",
            "[57,    50] loss: 0.370\n",
            "[57,   100] loss: 0.378\n",
            "[58,    50] loss: 0.299\n",
            "[58,   100] loss: 0.373\n",
            "[59,    50] loss: 0.374\n",
            "[59,   100] loss: 0.362\n",
            "[60,    50] loss: 0.304\n",
            "[60,   100] loss: 0.391\n",
            "[61,    50] loss: 0.359\n",
            "[61,   100] loss: 0.291\n",
            "[62,    50] loss: 0.370\n",
            "[62,   100] loss: 0.301\n",
            "[63,    50] loss: 0.292\n",
            "[63,   100] loss: 0.311\n",
            "[64,    50] loss: 0.265\n",
            "[64,   100] loss: 0.354\n",
            "[65,    50] loss: 0.311\n",
            "[65,   100] loss: 0.293\n",
            "[66,    50] loss: 0.305\n",
            "[66,   100] loss: 0.293\n",
            "[67,    50] loss: 0.301\n",
            "[67,   100] loss: 0.257\n",
            "[68,    50] loss: 0.285\n",
            "[68,   100] loss: 0.332\n",
            "[69,    50] loss: 0.353\n",
            "[69,   100] loss: 0.289\n",
            "[70,    50] loss: 0.268\n",
            "[70,   100] loss: 0.319\n",
            "[71,    50] loss: 0.323\n",
            "[71,   100] loss: 0.265\n",
            "[72,    50] loss: 0.278\n",
            "[72,   100] loss: 0.289\n",
            "[73,    50] loss: 0.294\n",
            "[73,   100] loss: 0.267\n",
            "[74,    50] loss: 0.314\n",
            "[74,   100] loss: 0.288\n",
            "[75,    50] loss: 0.302\n",
            "[75,   100] loss: 0.251\n",
            "[76,    50] loss: 0.328\n",
            "[76,   100] loss: 0.302\n",
            "[77,    50] loss: 0.287\n",
            "[77,   100] loss: 0.287\n",
            "[78,    50] loss: 0.251\n",
            "[78,   100] loss: 0.293\n",
            "[79,    50] loss: 0.251\n",
            "[79,   100] loss: 0.299\n",
            "[80,    50] loss: 0.255\n",
            "[80,   100] loss: 0.272\n",
            "[81,    50] loss: 0.255\n",
            "[81,   100] loss: 0.318\n",
            "[82,    50] loss: 0.257\n",
            "[82,   100] loss: 0.269\n",
            "[83,    50] loss: 0.308\n",
            "[83,   100] loss: 0.269\n",
            "[84,    50] loss: 0.288\n",
            "[84,   100] loss: 0.262\n",
            "[85,    50] loss: 0.235\n",
            "[85,   100] loss: 0.268\n",
            "[86,    50] loss: 0.285\n",
            "[86,   100] loss: 0.261\n",
            "[87,    50] loss: 0.268\n",
            "[87,   100] loss: 0.241\n",
            "[88,    50] loss: 0.266\n",
            "[88,   100] loss: 0.258\n",
            "[89,    50] loss: 0.240\n",
            "[89,   100] loss: 0.228\n",
            "[90,    50] loss: 0.268\n",
            "[90,   100] loss: 0.241\n",
            "[91,    50] loss: 0.228\n",
            "[91,   100] loss: 0.272\n",
            "[92,    50] loss: 0.254\n",
            "[92,   100] loss: 0.270\n",
            "[93,    50] loss: 0.243\n",
            "[93,   100] loss: 0.228\n",
            "[94,    50] loss: 0.211\n",
            "[94,   100] loss: 0.260\n",
            "[95,    50] loss: 0.273\n",
            "[95,   100] loss: 0.228\n",
            "[96,    50] loss: 0.267\n",
            "[96,   100] loss: 0.273\n",
            "[97,    50] loss: 0.233\n",
            "[97,   100] loss: 0.227\n",
            "[98,    50] loss: 0.305\n",
            "[98,   100] loss: 0.241\n",
            "[99,    50] loss: 0.210\n",
            "[99,   100] loss: 0.282\n",
            "[100,    50] loss: 0.260\n",
            "[100,   100] loss: 0.248\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYqIrQW_IKJf"
      },
      "source": [
        "trained_model_file = F'/content/gdrive/MyDrive/PhD/Coursework/AI in Genomics/Projects/Phyla/phyla_dataset_d3/trained_model.pth'\r\n",
        "torch.save(model.state_dict(), trained_model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1QeMyKR2wGC"
      },
      "source": [
        "model = LogisticRegression(num_genes)\r\n",
        "model.load_state_dict(torch.load(trained_model_file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAP5_rwH2zvp",
        "outputId": "9998deba-f8ec-4151-afc0-5334142964fd"
      },
      "source": [
        "print('Accuracy of the network on the ' + str(len(train_dataset)) + ' train samples: %d %%' % compute_accuracy(train_loader, model))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 3686 train samples: 92 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfKR2_wN22n_",
        "outputId": "fd65d98a-87c4-4784-aacb-246367f90775"
      },
      "source": [
        "print('Accuracy of the network on the ' + str(len(test_dataset)) + ' test samples: %d %%' % compute_accuracy(test_loader, model))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 1581 test samples: 88 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}